{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "This tutorial explains how to :\n",
    "- Prepare experiments for two models with different scalers and set up an experiments\n",
    "- Train the model\n",
    "- Compare model results thanks to tensorboard\n",
    "- Generate validation data and perform unscaling process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of two convolutional network\n",
    "First go to src\\model\\components\\conv1d_surr.py and read the model component definition.\n",
    "\n",
    "Then you can compare the conv1d_surr model with the conv1d_surr_nopca one.\n",
    "for conv1d_surr_nopca no PCA is shall be used during pre-processing. src\\model\\components\\conv1d_surr_nopca.py\n",
    "\n",
    "Open now the files configs\\model_net\\conv1d_surr_nopca.yaml and configs\\model_net\\conv1d_surr.yaml.\n",
    "\n",
    "User parameters to instanciate the models are defined inside them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new experiment files\n",
    "Run the code below to create two new experiment files.\n",
    "When running an experiment with train.py, you run the defaults parameters defined in the train.yaml file but you overide parameters specified in the experiment file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "\n",
    "# create a dictionary with the parameters\n",
    "header = '# @package _global_'\n",
    "Document = \"\"\"\n",
    "defaults:\n",
    "   - override /model_net: conv1d_surr.yaml\n",
    "task_name: \"tutorial\"\n",
    "preprocessing:\n",
    "   perform_decomp : True\n",
    "   \n",
    "tags: [\"surrogate\", \"conv1d\", \"PCA\"]\n",
    "\"\"\"\n",
    "\n",
    "# The above experiment will use the 'conv1d_surr' model.\n",
    "# It will outputs the results in the folder 'outputs\\tutorial'.\n",
    "# The default decomposition which is a PCA will be performed during pre-processing.\n",
    "# The experiments tags, accessible in Tensorboard visualisation will be \"surrogate\", \"conv1d\", \"PCA\"\n",
    "\n",
    "yaml_doc = yaml.load(Document, Loader=Loader)\n",
    "\n",
    "# write the dictionary to a yaml file\n",
    "with open('../configs/experiment/tuto_conv_pca.yaml', 'w') as f:\n",
    "    f.write(header+'\\n')\n",
    "    yaml.dump(yaml_doc, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/experiment/tuto_conv_nopca.yaml', 'w') as f :\n",
    "    Document = \"\"\"\n",
    "    defaults:\n",
    "        - override /model_net: conv1d_surr_nopca.yaml\n",
    "    task_name: \"tutorial\"\n",
    "    preprocessing:\n",
    "        perform_decomp : False\n",
    "    tags: [\"surrogate\", \"conv1d\", \"NoPCA\"]\n",
    "    \"\"\"\n",
    "    yaml_doc = yaml.load(Document, Loader=Loader)\n",
    "    f.write(header+'\\n')\n",
    "    yaml.dump(yaml_doc, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train both models\n",
    "Now open a python terminal and run the code below in the root directory of the project :\n",
    "```bash\n",
    "python src/train.py experiment=tuto_conv_pca.yaml\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the logs in the terminal.\n",
    "Full hydra output files are copied in a new folder of outputs\\tutorial\\runs.    \n",
    "Note that you defined the tutorial folder by specifying the task_name: \"tutorial\" in the experiment yaml file.    \n",
    "\n",
    "**You can order your experiments by task_name and model type to compare the models with tensorboard more easily.**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now run the code below in the root directory of the project :\n",
    "```bash\n",
    "python src/train.py experiment=tuto_conv_nopca.yaml\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models with tensorboard\n",
    "\n",
    "When training is over, you can see the results in tensorboard by running the code below in the root directory of the project :\n",
    "```bash\n",
    "tensorboard --logdir outputs\\tutorial\\runs\n",
    "```\n",
    "\n",
    "Open a browser and go to :\n",
    "http://localhost:6006/\n",
    "\n",
    "Now open the time series tab and compare the results of the two models.\n",
    "open the train card to see the training results and the validation card to see the validation results.\n",
    "Now open the HPARAMS tab and compare the hyperparameters of the two models.\n",
    "\n",
    "Scroll down the hyperparameters and activate tags and hp_metric.\n",
    "Now you can identify which model use a PCA and compare the metrics of both models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform inference and unscaling\n",
    "Now we will generate validation data and perform unscaling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "c:\\Users\\romain.ribault\\Anaconda3\\envs\\dmltp\\lib\\site-packages\\pkg_resources\\__init__.py:122: PkgResourcesDeprecationWarning: -0.1.0- is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"surrogate_inference.py\", line 231, in <module>\n",
      "    load_env_file(f\"env.yaml\")\n",
      "  File \"c:\\Users\\romain.ribault\\Documents\\GitHub\\torchydra\\src\\utils\\load_env_file.py\", line 5, in load_env_file\n",
      "    with open(path, 'r') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'env.yaml'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../src')\n",
    "\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Define the command to run\n",
    "command = [\"python\", \"surrogate_inference.py\"]\n",
    "\n",
    "# Execute the command within a subprocess\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "# Read and print the output dynamically\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "\n",
    "# Wait for the process to finish\n",
    "process.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmltp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
